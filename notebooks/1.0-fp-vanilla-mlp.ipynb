{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "df092198-2c1a-449c-94d6-0a52674b2e4c",
   "metadata": {},
   "source": [
    "# 0) Importing libraries and data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c49b2f26-52b9-409a-9cfa-a1f704c9320f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pytorch_lightning as pl\n",
    "\n",
    "from pytorch_lightning import seed_everything\n",
    "from pytorch_lightning.callbacks import EarlyStopping\n",
    "from pytorch_lightning.loggers import TensorBoardLogger\n",
    "from torch.optim.lr_scheduler import StepLR\n",
    "from sklearn.metrics import r2_score, mean_squared_error\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from torch.utils.data import TensorDataset, DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33eb93aa-e055-49e5-9b70-c154238c65c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "seed_everything(1996, workers=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e607ec13-98fb-417f-a609-89c8d1121f9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "if torch.cuda.is_available():\n",
    "    print(\"CUDA is available. Using GPU.\")\n",
    "    device = torch.device(\"cuda\")\n",
    "else:\n",
    "    print(\"CUDA is not available. Using CPU.\")\n",
    "    device = torch.device(\"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40155ce2-a8aa-4807-b520-7198ca24ee59",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dir = '../data/train_set.xlsx'\n",
    "test_dir = '../data/test_set.xlsx'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41e8382b-4f10-4edd-8a2a-3139ef0585e3",
   "metadata": {},
   "source": [
    "# 1) Create PL data module"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "714ca967-0a8d-4cd2-ac44-c7e3841a489d",
   "metadata": {},
   "outputs": [],
   "source": [
    "class NASAPOWERDataModule(pl.LightningDataModule):\n",
    "    \"\"\"\n",
    "    A PyTorch Lightning Data Module for handling NASA POWER data for ET0 prediction.\n",
    "    \n",
    "    This class is responsible for preparing and loading the dataset used in the et0 prediction model.\n",
    "    It includes methods for data preparation, setup, and creating PyTorch DataLoaders for the training, v\n",
    "    alidation, and test datasets.\n",
    "    \n",
    "    Attributes:\n",
    "        train_dir (str): The file path to the training dataset.\n",
    "        test_dir (str): The file path to the testing dataset.\n",
    "        batch_size (int): The size of the batches for the DataLoader.\n",
    "        train_split (float): The proportion of the data to be used for training.\n",
    "    \n",
    "    Methods:\n",
    "        prepare_data():\n",
    "            Reads and preprocesses the data from the file paths specified by train_dir and test_dir.\n",
    "        \n",
    "        setup(stage=None):\n",
    "            Prepares the data for training, validation, and testing. This method is responsible for \n",
    "            splitting the data and applying any transformations.\n",
    "        \n",
    "        train_dataloader():\n",
    "            Returns a DataLoader for the training dataset.\n",
    "        \n",
    "        val_dataloader():\n",
    "            Returns a DataLoader for the validation dataset.\n",
    "        \n",
    "        test_dataloader():\n",
    "            Returns a DataLoader for the test dataset.\n",
    "    \"\"\"\n",
    "    def __init__(self, train_dir: str, test_dir: str, batch_size=32, train_split=0.7):\n",
    "        super().__init__()\n",
    "        self.train_dir = train_dir\n",
    "        self.test_dir = test_dir\n",
    "        self.batch_size = batch_size\n",
    "        self.train_split = train_split\n",
    "\n",
    "    def prepare_data(self):\n",
    "        # read, process and split training dataset\n",
    "        df_train = pd.read_excel(self.train_dir)\n",
    "        X = df_train.drop('HS', axis=1).values\n",
    "        y = df_train['HS'].values\n",
    "        scaler = StandardScaler()\n",
    "        X_scaled = scaler.fit_transform(X) # scale features\n",
    "        X_train, X_val, y_train, y_val = train_test_split(X_scaled, y,\n",
    "                                                          test_size = 1 - self.train_split,\n",
    "                                                          random_state=123)\n",
    "        self.X_train = torch.tensor(X_train, dtype=torch.float32)\n",
    "        self.y_train = torch.tensor(y_train, dtype=torch.float32).unsqueeze(-1)\n",
    "        self.X_val = torch.tensor(X_val, dtype=torch.float32)\n",
    "        self.y_val = torch.tensor(y_val, dtype=torch.float32).unsqueeze(-1)\n",
    "\n",
    "        # read and process testing dataset\n",
    "        df_test = pd.read_excel(self.test_dir)\n",
    "        X_test = df_test.drop('ET', axis=1).values\n",
    "        y_test = df_test['ET'].values\n",
    "        X_test_scaled = scaler.transform(X_test) # !!!\n",
    "        self.X_test = torch.tensor(X_test_scaled, dtype=torch.float32)\n",
    "        self.y_test = torch.tensor(y_test, dtype=torch.float32).unsqueeze(-1)\n",
    "\n",
    "    def setup(self, stage=None):\n",
    "        if stage == 'fit' or stage is None:\n",
    "            self.train_dataset = TensorDataset(self.X_train, self.y_train)\n",
    "            self.val_dataset = TensorDataset(self.X_val, self.y_val)\n",
    "        if stage == 'test' or stage is None:\n",
    "            self.test_dataset = TensorDataset(self.X_test, self.y_test)\n",
    "\n",
    "    def train_dataloader(self):\n",
    "        return DataLoader(self.val_dataset, batch_size=self.batch_size,\n",
    "                          num_workers=1)\n",
    "\n",
    "    def val_dataloader(self):\n",
    "        return DataLoader(self.val_dataset, batch_size=self.batch_size,\n",
    "                          num_workers=1)\n",
    "\n",
    "    def test_dataloader(self):\n",
    "        return DataLoader(self.test_dataset, batch_size=self.batch_size,\n",
    "                          num_workers=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f575ce8f-4d08-4854-a70f-222cf34b3730",
   "metadata": {},
   "source": [
    "# 2) Model implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fd9def9",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LitModel(pl.LightningModule):\n",
    "    \"\"\"\n",
    "    A PyTorch Lightning Module for the et0 prediction model using NASA POWER data.\n",
    "\n",
    "    This class encapsulates the model architecture, training step, validation step, and configuration\n",
    "      of optimizers. It's designed for easy experimentation with different model architectures and \n",
    "      training routines using the PyTorch Lightning framework.\n",
    "\n",
    "    Attributes:\n",
    "        model (torch.nn.Module): The neural network model to be trained.\n",
    "        loss_fn (Callable): The loss function used for training the model.\n",
    "        lr (float): Learning rate for the optimizer.\n",
    "\n",
    "    Methods:\n",
    "        forward(x):\n",
    "            Defines the forward pass of the model.\n",
    "        \n",
    "        training_step(batch, batch_idx):\n",
    "            Conducts a single training step, including forward pass, loss calculation, and logging.\n",
    "        \n",
    "        validation_step(batch, batch_idx):\n",
    "            Conducts a single validation step, including forward pass and loss calculation.\n",
    "        \n",
    "        configure_optimizers():\n",
    "            Configures the model's optimizers and learning rate scheduler.\n",
    "    \"\"\"\n",
    "    def __init__(self, model, lr=0.01):\n",
    "        super().__init__()\n",
    "        self.model = model\n",
    "        self.learning_rate = lr\n",
    "        self.test_outputs = []\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.model.forward(x)\n",
    "\n",
    "    def training_step(self, train_batch, batch_idx):\n",
    "        x, y = train_batch\n",
    "        y_pred = self(x)\n",
    "        loss = nn.MSELoss()(y_pred, y)\n",
    "\n",
    "        # check for NaN values\n",
    "        if torch.isnan(loss):\n",
    "            print(f\"NaN detected at epoch {self.current_epoch}, batch {batch_idx}\")\n",
    "\n",
    "        self.log('train_loss', loss,\n",
    "                 prog_bar=True, on_step=False,\n",
    "                 on_epoch=True)\n",
    "        return loss\n",
    "\n",
    "    def validation_step(self, val_batch, batch_idx):\n",
    "        x, y = val_batch\n",
    "        y_pred = self(x)\n",
    "        loss = nn.MSELoss()(y_pred, y)\n",
    "        self.log('val_loss', loss,\n",
    "                 prog_bar=True, on_step=False,\n",
    "                 on_epoch=True)\n",
    "        return loss # !!!\n",
    "\n",
    "    def test_step(self, batch, batch_idx):\n",
    "        x, y = batch\n",
    "        y_pred = self(x)\n",
    "        loss = nn.MSELoss()(y_pred, y)\n",
    "        self.test_outputs.append({'y_pred': y_pred.detach(), 'y_true': y.detach()})\n",
    "\n",
    "        return {'y_pred': y_pred.detach(), 'y_true': y.detach()}\n",
    "\n",
    "    def on_test_epoch_end(self):\n",
    "        # Aggregate outputs\n",
    "        all_outputs = self.all_gather(self.test_outputs)\n",
    "\n",
    "        # Concatenate all y_pred and y_true from each test step\n",
    "        y_pred = torch.cat([tmp['y_pred'] for tmp in all_outputs], dim=0)\n",
    "        y_true = torch.cat([tmp['y_true'] for tmp in all_outputs], dim=0)\n",
    "\n",
    "        # Convert to numpy arrays for calculation with sklearn\n",
    "        y_pred_np = y_pred.cpu().numpy()\n",
    "        y_true_np = y_true.cpu().numpy()\n",
    "\n",
    "        # Calculate metrics\n",
    "        r2 = r2_score(y_true_np, y_pred_np)\n",
    "        rmse = mean_squared_error(y_true_np, y_pred_np, squared=False)\n",
    "        nrmse = rmse / np.mean(y_true_np)\n",
    "\n",
    "        # Log metrics\n",
    "        self.log('test_r2', r2)\n",
    "        self.log('test_rmse', rmse)\n",
    "        self.log('test_nrmse', nrmse)\n",
    "\n",
    "        # store predictions and actual observations\n",
    "        self.predictions = y_pred_np\n",
    "        self.actuals = y_true_np\n",
    "\n",
    "        # store metrics\n",
    "        self.metrics = {'R2': r2, 'RMSE': rmse, 'nRMSE': nrmse}\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        optimizer = torch.optim.Adam(self.model.parameters(),\n",
    "                                    self.learning_rate,\n",
    "                                    weight_decay=0.01)\n",
    "        return optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d47579e",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MLP(nn.Module):\n",
    "    \"\"\"\n",
    "    A multilayer perceptron (MLP) model designed for regression tasks, \n",
    "    implemented using PyTorch's neural network module.\n",
    "\n",
    "    This class defines a simple feedforward neural network with three linear layers, \n",
    "    ReLU activations, and dropout for regularization. It's suitable for tasks like \n",
    "    predicting continuous variables from a given set of input features.\n",
    "\n",
    "    Attributes:\n",
    "        input_size (int): The number of input features the model expects.\n",
    "        dropout_rate (float): The dropout rate used in the dropout layers for regularization.\n",
    "\n",
    "    Methods:\n",
    "        forward(x):\n",
    "            Defines the forward pass of the model. Takes an input tensor `x` and returns the model's output tensor.\n",
    "\n",
    "    Example:\n",
    "        >>> model = MLPModel(input_size=10, dropout_rate=0.5)\n",
    "        >>> print(model)\n",
    "        MLPModel(\n",
    "          (fc1): Linear(in_features=10, out_features=256, bias=True)\n",
    "          (fc2): Linear(in_features=256, out_features=128, bias=True)\n",
    "          (fc3): Linear(in_features=128, out_features=1, bias=True)\n",
    "          (relu): ReLU()\n",
    "          (dropout): Dropout(p=0.5, inplace=False)\n",
    "        )\n",
    "    \"\"\"\n",
    "    def __init__(self, input_size=10):\n",
    "        super(MLP, self).__init__()\n",
    "        self.fc1 = nn.Linear(input_size, 256)\n",
    "        self.fc2 = nn.Linear(256, 128)\n",
    "        self.fc3 = nn.Linear(128, 1)\n",
    "        self.dropout = nn.Dropout(0.5)\n",
    "        self.relu = nn.ReLU()\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.relu(self.fc1(x))\n",
    "        x = self.dropout(x)\n",
    "        x = self.relu(self.fc2(x))\n",
    "        x = self.dropout(x)\n",
    "        x = self.fc3(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae1c3dc5",
   "metadata": {},
   "source": [
    "# 3) Model training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3dc57d81",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_epochs = 100\n",
    "data_module = NASAPOWERDataModule(train_dir=train_dir, test_dir=test_dir)\n",
    "mlp_instance = MLP(input_size=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19a35bbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = LitModel(mlp_instance,\n",
    "                 lr=0.012022644346174132)\n",
    "early_stop_callback = EarlyStopping(monitor=\"val_loss\",\n",
    "                                    min_delta=0.00,\n",
    "                                    patience=10,\n",
    "                                    verbose=True,\n",
    "                                    mode=\"min\")\n",
    "trainer = pl.Trainer(max_epochs=num_epochs,\n",
    "                     log_every_n_steps=10,\n",
    "                     detect_anomaly=False,\n",
    "                     callbacks=[early_stop_callback])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8c0da4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialize TensorBoard logger\n",
    "log_name = \"vanilla_mlp\"\n",
    "logger = TensorBoardLogger(\"lightning_logs\", name=log_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b253bca1",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.fit(model, data_module)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0dbf0e2",
   "metadata": {},
   "source": [
    "## 3.1) Visualise loss curves"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "feb1ce61",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext tensorboard\n",
    "%tensorboard --logdir ./lightning_logs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a7e3d5a",
   "metadata": {},
   "source": [
    "# 4) Model testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef033b02",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.test(model, data_module)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5fe315b",
   "metadata": {},
   "source": [
    "### 4.2 Plot results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26603007",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(6, 6))\n",
    "plt.scatter(model.actuals, model.predictions, alpha=0.5)\n",
    "plt.xlabel('Predicted ETo (mm/month)', fontsize=18)\n",
    "plt.ylabel('Observed ETo (mm/month)', fontsize=18)\n",
    "plt.title('Predicted vs Observed (Testing)', fontsize=18)\n",
    "plt.plot([min(model.actuals), max(model.actuals)], \n",
    "         [min(model.actuals), max(model.actuals)], \n",
    "         'r--')\n",
    "\n",
    "# put metrics in the plot\n",
    "metrics_text = '\\n'.join([f'{key}: {value:.2f}' for key, value in model.metrics.items()])\n",
    "plt.annotate(metrics_text, xy=(0.05, 0.8), \n",
    "             xycoords='axes fraction', \n",
    "             bbox=dict(boxstyle=\"round\", \n",
    "                       fc=\"w\"))\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
